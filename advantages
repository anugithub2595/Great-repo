
Required Skill set:
Experience in Building the cloud infra on Data Engg
Experience in AWS, Spark &amp; Kafka, Python skill will be an advantage
Able to setup the infra CI/CD; Automating the Data Processing, Data Pipelining
A good understanding of the different data needs of analytics and engineering teams and how they could be met. Ideally, you have already successfully supported analytics and/or engineering teams with data platform capabilities.
You effectively enabled &amp; trained others to work with the data tools and services you provided.
You used or ideally managed message brokers (like Kafka) to share data updates across services and applications.
You have a solid understanding of software design principles and DevOps.
You have a solid understanding of distributed processing systems such as Apache spark or any other such tech.
You have experience with Infrastructure as Code tools such as terraform or terragrunt.
Ideally, you have production experience in AWS.
You are a self-starter who is comfortable working autonomously and with teams located across our offices. You’re not afraid to get your hands dirty, prioritize your focus based on impact, and are able to own a project from start to finish
Nice to have:
Production experience with machine learning (MLOps) or containerised
solutions (Docker/Kubernetes).
You have a strong foundation in Python and SQL.
A major part of the work is to develop our core data platform functionality to enable data professionals and product teams with easy access to relevant data,interfaces, and functionality for reliably processing, storing and publishing data.
This is the tricky point, that we are looking for people to build a platform instead of people that are proficient in using them.
Required Skill set:
Experience in Building the cloud infra on Data Engg
Experience in AWS, Spark &amp; Kafka, Python skill will be an advantage
Able to setup the infra CI/CD; Automating the Data Processing, Data Pipelining
A good understanding of the different data needs of analytics and engineering teams and how they could be met. Ideally, you have already successfully supported analytics and/or engineering teams with data platform capabilities.
You effectively enabled &amp; trained others to work with the data tools and services you provided.
You used or ideally managed message brokers (like Kafka) to share data updates across services and applications.
You have a solid understanding of software design principles and DevOps.
You have a solid understanding of distributed processing systems such as Apache spark or any other such tech.
You have experience with Infrastructure as Code tools such as terraform or terragrunt.
Ideally, you have production experience in AWS.
You are a self-starter who is comfortable working autonomously and with teams located across our offices. You’re not afraid to get your hands dirty, prioritize your focus based on impact, and are able to own a project from start to finish
Nice to have:
Production experience with machine learning (MLOps) or containerised
solutions (Docker/Kubernetes).
You have a strong foundation in Python and SQL.
A major part of the work is to develop our core data platform functionality to enable data professionals and product teams with easy access to relevant data,interfaces, and functionality for reliably processing, storing and publishing data.
This is the tricky point, that we are looking for people to build a platform instead of people that are proficient in using them.
